{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation and Preprocessing\n",
    "\n",
    "### Importing Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install matplotlib\n",
    "%pip install imutils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping and Noise Handling\n",
    "\n",
    "To enrich the data that is going into our networks, we zoomed into our important data by cropping out insignificant data in our images (blanks spaces not near the brain). We used a cropping technique to find the extreme ends (top, bottom, left, right) of the brain contours and used them to crop out the rest of the image. \n",
    "Reference article used: https://www.pyimagesearch.com/2016/04/11/finding-extreme-points-in-contours-with-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_brain_region(image, plot=False):\n",
    "    \"\"\"Function for Image Cropping and Noise Elimination\"\"\"\n",
    "\n",
    "    # IMG grayed (focus on intensity variations)\n",
    "    grayed_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # IMG blurred (smoother and noise reduction), applied a kernel of 5,5 and sigma of\n",
    "    blurred_img = cv2.GaussianBlur(grayed_img, (5, 5), 0)\n",
    "\n",
    "    # Threshold the image, then perform a series of erosions +\n",
    "    # dilations to remove any small regions of noise\n",
    "\n",
    "    # IMG threshold to segregate image binary regions based on pixel intensity, separate objects of interests from background, used 45 avg threshold value, 255 max value\n",
    "    threshed_img = cv2.threshold(blurred_img, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    # IMG eroded then dilated to first remove noise (by shrinking or eroding boundaries of objects) then enlarge again to original object boundaries\n",
    "    eroded_img = cv2.erode(threshed_img, None, iterations=2)\n",
    "    dilated_img = cv2.dilate(eroded_img, None, iterations=2)\n",
    "\n",
    "    # Find contours in thresholded image\n",
    "    cnts = cv2.findContours(dilated_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Grab the largest contour\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    \n",
    "\n",
    "    # Define the extreme points of the contours (used to determine where to crop)\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "    \n",
    "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
    "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]        \n",
    "\n",
    "    # Optional plotting for visualization\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "        plt.title('Original Image')\n",
    "            \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(new_image)\n",
    "        plt.tick_params(axis='both', which='both', \n",
    "                        top=False, bottom=False, left=False, right=False,\n",
    "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "        plt.title('Cropped Image')\n",
    "\n",
    "        plt.show()\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading inputs and labels, Resizing and Normalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_directory(directory, label, x, y):\n",
    "    \"\"\"Function used to process images from data directories to assign them to the x_input and y_output variables\"\"\"\n",
    "\n",
    "    # Define image size as 128 x 128 pixel size\n",
    "    image_size = (128,128)\n",
    "\n",
    "    # Traverse through the data directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Traverse through each image within each directory\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        image = cv2.imread(filepath)\n",
    "        # Crops brain, resizes images and normalizes values\n",
    "        if image is not None:\n",
    "            image = crop_brain_region(image, plot=False)\n",
    "            image = cv2.resize(image, dsize=image_size, interpolation=cv2.INTER_CUBIC)\n",
    "            # Normalize values to a range between 0 and 1 instead of 0 - 255\n",
    "            image = image / 255.0\n",
    "            # Append the image and its corresponding labels label to the x input and y output lists\n",
    "            x.append(image)\n",
    "            y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each processed images are stored here\n",
    "x_input = [] \n",
    "# Each images' corresponding labels are stored here\n",
    "y_output = []       \n",
    "\n",
    "# Process and Load all the images into the x and y variables\n",
    "process_image_directory(\"data/notumor\", 0, x_input, y_output)\n",
    "process_image_directory(\"data/glioma\", 1, x_input, y_output)\n",
    "process_image_directory(\"data/meningioma\", 2, x_input, y_output)\n",
    "process_image_directory(\"data/pituitary\", 3, x_input, y_output)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "x_input_np = np.array(x_input)\n",
    "y_output_np = np.array(y_output)\n",
    "\n",
    "# Sample output\n",
    "print(x_input_np)\n",
    "print(y_output_np)\n",
    "\n",
    "# Get rough dimensions (number of data, pixel sizes) of the data\n",
    "print(x_input_np.shape)\n",
    "print(y_output_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(X, y, n=50):\n",
    "    \"\"\"\n",
    "    Plots n sample images for each unique label in y.\n",
    "    Arguments:\n",
    "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
    "        y: A numpy array with shape = (#_examples, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a mapping from label to string representation\n",
    "    label_to_str = {0: \"No Tumor\", 1: \"Glioma\", 2: \"Meningioma\", 3: \"Pituitary\"}\n",
    "    \n",
    "    # Iterate over all unique labels in y\n",
    "    for label in np.unique(y):\n",
    "        # Grab the first n images with the corresponding y values equal to label\n",
    "        images = X[np.argwhere(y == label)]\n",
    "        n_images = images[:n]\n",
    "        \n",
    "        columns_n = 10\n",
    "        rows_n = int(np.ceil(n / columns_n))\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        i = 1  # Current plot        \n",
    "        for image in n_images:\n",
    "            plt.subplot(rows_n, columns_n, i)\n",
    "            plt.imshow(image[0])\n",
    "            \n",
    "            # Remove ticks\n",
    "            plt.tick_params(axis='both', which='both', \n",
    "                            top=False, bottom=False, left=False, right=False,\n",
    "                            labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        plt.suptitle(f\"Tumor Type: {label_to_str[label]}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples of 10 images of original data from each class\n",
    "plot_sample_images(x_input_np, y_output_np, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "To obtain a bigger dataset by 300% for better model performance and to avoid overfitting, we decided to augment our original data by\n",
    "- Randomly Rotating our original Images from -25 to 25 degrees\n",
    "- Vertically Flipped our original images\n",
    "- Horziotally Flipped our original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotate(image, max_angle=25):\n",
    "    \"\"\"Function that return an img that has been randomly rotated between -25 to 25 degrees\"\"\"\n",
    "    # Generate a random angle between -25 to 25 degrees\n",
    "    angle = np.random.uniform(-max_angle, max_angle)\n",
    "    rows, cols, _ = image.shape\n",
    "    # Rotate the image\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    return cv2.warpAffine(image, M, (cols, rows))\n",
    "\n",
    "def augment_data(images, labels):\n",
    "    \"\"\"Function that augment all images and returns all augments and its labels\"\"\"\n",
    "    # Stores augmented images\n",
    "    augmented_images  = []\n",
    "    # Stores labels of corresponding augmented images\n",
    "    augmented_labels = []\n",
    "\n",
    "    for img, label in zip(images, labels):\n",
    "        # Create a vertically flipped version\n",
    "        vertical_flip = np.flipud(img)\n",
    "        augmented_images.append(vertical_flip)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # Create a horizontally flipped version\n",
    "        horizontal_flip = np.fliplr(img)\n",
    "        augmented_images.append(horizontal_flip)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "        # Create a randomly rotated version\n",
    "        random_rotation = random_rotate(img)\n",
    "        augmented_images.append(random_rotation)\n",
    "        augmented_labels.append(label)\n",
    "\n",
    "    return np.array(augmented_images), np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment your input data\n",
    "augmented_x_input_np, augmented_y_output_np = augment_data(x_input_np, y_output_np)\n",
    "\n",
    "# Get rough dimensions of augmented data\n",
    "print(augmented_x_input_np.shape)\n",
    "print(augmented_y_output_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples of 30 images of augmented data from each class\n",
    "plot_sample_images(augmented_x_input_np, augmented_y_output_np, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data and Exporting outputs\n",
    "\n",
    "All preprocessed data are combined and are exported into numpy format stored in directory prepared_data. You can access them and just see how to manipulate them using test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the original and augmented data for both x_inputs and y_outputs\n",
    "x_input_combined_np = np.concatenate((x_input_np, augmented_x_input_np), axis=0)\n",
    "y_output_combined_np = np.concatenate((y_output_np, augmented_y_output_np), axis=0)\n",
    "\n",
    "# Save merged data as NumPy arrays\n",
    "np.save(\"prepared_data/x_input_combined.npy\", x_input_combined_np)\n",
    "np.save(\"prepared_data/y_output_combined.npy\", y_output_combined_np)\n",
    "\n",
    "# Save it in CSV Format just for checking\n",
    "x_input_combined_2d = x_input_combined_np.reshape(-1, 1)\n",
    "np.savetxt(\"prepared_data/x_input_combined.txt\", x_input_combined_2d, delimiter=\",\")\n",
    "# np.savetxt(\"prepared_data/x_input_combined.txt\", x_input_combined_np, delimiter=\",\")\n",
    "np.savetxt(\"prepared_data/y_output_combined.txt\", y_output_combined_np, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dependencies",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
